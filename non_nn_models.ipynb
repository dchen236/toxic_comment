{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Decision Tree</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/danni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/danni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def preprocess(data):\n",
    "    '''                                                                         \n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution   \n",
    "    '''\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°\\\n",
    "£€\\×™√²—–&'\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = clean_special_chars(str(data), punct)\n",
    "    data = data.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned = [word for word in data if word not in stop_words]\n",
    "    return \" \".join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = True\n",
    "if cleaned:\n",
    "    train_file = \"preprocessed_train.csv\"\n",
    "    df = pd.read_csv(train_file)\n",
    "else:\n",
    "    train_file = \"train.csv\"\n",
    "    df = pd.read_csv(train_file)\n",
    "    df['clean_text'] = df['comment_text'].apply(lambda x: preprocess(x))\n",
    "    df.to_csv(\"preprocessed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evluation metrics\n",
    "# From baseline kernel\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]>0.5\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "\n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]>0.5]\n",
    "    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n",
    "    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n",
    "    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test data\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 42)\n",
    "x_train = train['clean_text'].astype(str)\n",
    "x_test = test['clean_text'].astype(str)\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_test = np.where(test['target'] >= 0.5, 1, 0)\n",
    "#Encode training data with glove vectors\n",
    "glove = EmbeddingTransformer('glove')\n",
    "x_train = glove.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit LR model\n",
    "MODEL_NAME = 'LR'\n",
    "target_model = LogisticRegression(C=5, random_state=42, solver='sag', max_iter=1000, n_jobs=-1)\n",
    "target_model.fit(x_train, y_train)\n",
    "x_test_glove = glove.transform(x_test)\n",
    "predictions = target_model.predict_proba(x_test_glove)[:,1]\n",
    "\n",
    "val = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9174568875960939\n",
      "final auc  0.7587788675469529\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.825947</td>\n",
       "      <td>0.668087</td>\n",
       "      <td>black</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758089</td>\n",
       "      <td>0.760505</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.724064</td>\n",
       "      <td>3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.843873</td>\n",
       "      <td>0.646589</td>\n",
       "      <td>white</td>\n",
       "      <td>0.728359</td>\n",
       "      <td>4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842161</td>\n",
       "      <td>0.653064</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.789674</td>\n",
       "      <td>0.739740</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.749666</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.839600</td>\n",
       "      <td>0.690624</td>\n",
       "      <td>female</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>10136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.762437</td>\n",
       "      <td>0.778595</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.754917</td>\n",
       "      <td>1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852224</td>\n",
       "      <td>0.676963</td>\n",
       "      <td>male</td>\n",
       "      <td>0.763339</td>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733759</td>\n",
       "      <td>0.833909</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.791629</td>\n",
       "      <td>7011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "6  0.825947  0.668087                          black      0.723679   \n",
       "5  0.758089  0.760505                         muslim      0.724064   \n",
       "7  0.843873  0.646589                          white      0.728359   \n",
       "2  0.842161  0.653064      homosexual_gay_or_lesbian      0.734267   \n",
       "8  0.789674  0.739740  psychiatric_or_mental_illness      0.749666   \n",
       "1  0.839600  0.690624                         female      0.754354   \n",
       "4  0.762437  0.778595                         jewish      0.754917   \n",
       "0  0.852224  0.676963                           male      0.763339   \n",
       "3  0.733759  0.833909                      christian      0.791629   \n",
       "\n",
       "   subgroup_size  \n",
       "6           2729  \n",
       "5           3940  \n",
       "7           4661  \n",
       "2           2104  \n",
       "8            861  \n",
       "1          10136  \n",
       "4           1431  \n",
       "0           8025  \n",
       "3           7011  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "MODEL_NAME = 'LR'\n",
    "test[MODEL_NAME]= val[\"prediction\"]\n",
    "TOXICITY_COLUMN = 'target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test, identity_columns, MODEL_NAME, 'target')\n",
    "binary_labels = np.where(test[TOXICITY_COLUMN] >= 0.5, 1, 0)\n",
    "binary_preds = np.where(test[MODEL_NAME] >= 0.5, 1, 0)\n",
    "print(\"accuracy: \", (accuracy_score(binary_labels, binary_preds)))\n",
    "print(\"final auc \", get_final_metric(bias_metrics_df, calculate_overall_auc(test, MODEL_NAME)))\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Fit NB model\n",
    "MODEL_NAME = 'NB'\n",
    "target_model = GaussianNB()\n",
    "target_model.fit(x_train, y_train)\n",
    "x_test_glove = glove.transform(x_test)\n",
    "predictions = target_model.predict_proba(x_test_glove)[:,1]\n",
    "\n",
    "val = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8987658425098691\n",
      "final auc  0.714034769963206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.656839</td>\n",
       "      <td>0.721844</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.623098</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.796367</td>\n",
       "      <td>0.603896</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.657850</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.793092</td>\n",
       "      <td>0.621605</td>\n",
       "      <td>black</td>\n",
       "      <td>0.672298</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.723784</td>\n",
       "      <td>0.714569</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.677670</td>\n",
       "      <td>3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.601035</td>\n",
       "      <td>white</td>\n",
       "      <td>0.682683</td>\n",
       "      <td>4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741244</td>\n",
       "      <td>0.732741</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.721359</td>\n",
       "      <td>7011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.709661</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.728922</td>\n",
       "      <td>1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.836923</td>\n",
       "      <td>0.630849</td>\n",
       "      <td>female</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>10136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849821</td>\n",
       "      <td>0.607552</td>\n",
       "      <td>male</td>\n",
       "      <td>0.736357</td>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "8  0.656839  0.721844  psychiatric_or_mental_illness      0.623098   \n",
       "2  0.796367  0.603896      homosexual_gay_or_lesbian      0.657850   \n",
       "6  0.793092  0.621605                          black      0.672298   \n",
       "5  0.723784  0.714569                         muslim      0.677670   \n",
       "7  0.814156  0.601035                          white      0.682683   \n",
       "3  0.741244  0.732741                      christian      0.721359   \n",
       "4  0.765865  0.709661                         jewish      0.728922   \n",
       "1  0.836923  0.630849                         female      0.733822   \n",
       "0  0.849821  0.607552                           male      0.736357   \n",
       "\n",
       "   subgroup_size  \n",
       "8            861  \n",
       "2           2104  \n",
       "6           2729  \n",
       "5           3940  \n",
       "7           4661  \n",
       "3           7011  \n",
       "4           1431  \n",
       "1          10136  \n",
       "0           8025  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "MODEL_NAME = 'NB'\n",
    "test[MODEL_NAME]= val[\"prediction\"]\n",
    "TOXICITY_COLUMN = 'target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test, identity_columns, MODEL_NAME, 'target')\n",
    "binary_labels = np.where(test[TOXICITY_COLUMN] >= 0.5, 1, 0)\n",
    "binary_preds = np.where(test[MODEL_NAME] >= 0.5, 1, 0)\n",
    "print(\"accuracy: \", (accuracy_score(binary_labels, binary_preds)))\n",
    "print(\"final auc \", get_final_metric(bias_metrics_df, calculate_overall_auc(test, MODEL_NAME)))\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using linear kernel \n",
    "from sklearn import tree\n",
    "\n",
    "#Fit svm model\n",
    "MODEL_NAME = 'tree'\n",
    "target_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "target_model.fit(x_train, y_train)\n",
    "x_test_glove = glove.transform(x_test)\n",
    "predictions = target_model.predict_proba(x_test_glove)[:,1]\n",
    "\n",
    "val = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8630071334579957\n",
      "final auc  0.5748473499533646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.554963</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.553456</td>\n",
       "      <td>3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587537</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.561198</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.595721</td>\n",
       "      <td>0.545819</td>\n",
       "      <td>white</td>\n",
       "      <td>0.561731</td>\n",
       "      <td>4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.592515</td>\n",
       "      <td>0.558921</td>\n",
       "      <td>black</td>\n",
       "      <td>0.571647</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561114</td>\n",
       "      <td>0.594033</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.574780</td>\n",
       "      <td>7011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567808</td>\n",
       "      <td>0.588183</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586721</td>\n",
       "      <td>0.570366</td>\n",
       "      <td>female</td>\n",
       "      <td>0.576261</td>\n",
       "      <td>10136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594696</td>\n",
       "      <td>0.563981</td>\n",
       "      <td>male</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.582084</td>\n",
       "      <td>0.592325</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.594115</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "5  0.554963  0.581225                         muslim      0.553456   \n",
       "2  0.587537  0.554199      homosexual_gay_or_lesbian      0.561198   \n",
       "7  0.595721  0.545819                          white      0.561731   \n",
       "6  0.592515  0.558921                          black      0.571647   \n",
       "3  0.561114  0.594033                      christian      0.574780   \n",
       "4  0.567808  0.588183                         jewish      0.575537   \n",
       "1  0.586721  0.570366                         female      0.576261   \n",
       "0  0.594696  0.563981                           male      0.578675   \n",
       "8  0.582084  0.592325  psychiatric_or_mental_illness      0.594115   \n",
       "\n",
       "   subgroup_size  \n",
       "5           3940  \n",
       "2           2104  \n",
       "7           4661  \n",
       "6           2729  \n",
       "3           7011  \n",
       "4           1431  \n",
       "1          10136  \n",
       "0           8025  \n",
       "8            861  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "MODEL_NAME = 'svm'\n",
    "test[MODEL_NAME]= val[\"prediction\"]\n",
    "TOXICITY_COLUMN = 'target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test, identity_columns, MODEL_NAME, 'target')\n",
    "binary_labels = np.where(test[TOXICITY_COLUMN] >= 0.5, 1, 0)\n",
    "binary_preds = np.where(test[MODEL_NAME] >= 0.5, 1, 0)\n",
    "print(\"accuracy: \", (accuracy_score(binary_labels, binary_preds)))\n",
    "print(\"final auc \", get_final_metric(bias_metrics_df, calculate_overall_auc(test, MODEL_NAME)))\n",
    "bias_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
