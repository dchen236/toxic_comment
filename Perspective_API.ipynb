{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perspective_API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNUesu4B6nMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "12db6eae-f1e5-43a8-ee1e-ad2e49accc0c"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "\n",
        "import markdown\n",
        "import json\n",
        "import requests\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "!pip install colorama\n",
        "from colorama import Fore, Back, Style, init"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.12.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=ec0670d05fa225eaef2d3739725743d4192a0b1ea7110c0661aee90cddc392fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.8\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvSpGJq16qh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from html.parser import HTMLParser\n",
        "except ImportError:\n",
        "    from HTMLParser import HTMLParser\n",
        "\n",
        "def validate_language(language):\n",
        "    # ISO 639-1 code validation\n",
        "    # language source: https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n",
        "    codes = [\"ab\", \"aa\", \"ae\", \"af\", \"ak\", \"am\", \"an\", \"ar\", \"as\", \"av\", \"ay\",\n",
        "             \"az\", \"ba\", \"be\", \"bg\", \"bh\", \"bi\", \"bm\", \"bn\", \"bo\", \"br\", \"bs\",\n",
        "             \"ca\", \"ce\", \"ch\", \"co\", \"cr\", \"cs\", \"cu\", \"cv\", \"cy\", \"da\", \"de\",\n",
        "             \"dv\", \"dz\", \"ee\", \"el\", \"en\", \"eo\", \"es\", \"et\", \"eu\", \"fa\", \"ff\",\n",
        "             \"fi\", \"fj\", \"fo\", \"fr\", \"fy\", \"ga\", \"gd\", \"gl\", \"gn\", \"gu\", \"gv\",\n",
        "             \"ha\", \"he\", \"hi\", \"ho\", \"hr\", \"ht\", \"hu\", \"hy\", \"hz\", \"ia\", \"id\",\n",
        "             \"ie\", \"ig\", \"ii\", \"ik\", \"io\", \"is\", \"it\", \"iu\", \"ja\", \"jv\", \"ka\",\n",
        "             \"kg\", \"ki\", \"kj\", \"kk\", \"kl\", \"km\", \"kn\", \"ko\", \"kr\", \"ks\", \"ku\",\n",
        "             \"kv\", \"kw\", \"ky\", \"la\", \"lb\", \"lg\", \"li\", \"ln\", \"lo\", \"lt\", \"lu\",\n",
        "             \"lv\", \"mg\", \"mh\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\",\n",
        "             \"na\", \"nb\", \"nd\", \"ne\", \"ng\", \"nl\", \"nn\", \"no\", \"nr\", \"nv\", \"ny\",\n",
        "             \"oc\", \"oj\", \"om\", \"or\", \"os\", \"pa\", \"pi\", \"ps\", \"pt\", \"qu\", \"rm\",\n",
        "             \"rn\", \"ro\", \"ru\", \"rw\", \"sa\", \"sc\", \"sd\", \"se\", \"sg\", \"si\", \"sk\",\n",
        "             \"sl\", \"sm\", \"sn\", \"so\", \"sq\", \"sr\", \"ss\", \"st\", \"su\", \"sv\", \"sw\",\n",
        "             \"ta\", \"te\", \"tg\", \"th\", \"ti\", \"tk\", \"tl\", \"tn\", \"to\", \"tr\", \"ts\",\n",
        "             \"tt\", \"tw\", \"ty\", \"ug\", \"uk\", \"ur\", \"uz\", \"ve\", \"vi\", \"vo\", \"wa\",\n",
        "             \"wo\", \"xh\", \"yi\", \"yo\", \"za\", \"zh\", \"zu\"]\n",
        "    return language.lower() in codes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpQYBSTs78lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text, md=False):\n",
        "    if md:\n",
        "        text = markdown.markdown(text)\n",
        "    # credit: stackoverflow\n",
        "    class MLStripper(HTMLParser):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.reset()\n",
        "            self.strict = False\n",
        "            self.convert_charrefs= True\n",
        "            self.fed = []\n",
        "        def handle_data(self, d):\n",
        "            self.fed.append(d)\n",
        "        def get_data(self):\n",
        "            return ''.join(self.fed)\n",
        "\n",
        "    s = MLStripper()\n",
        "    s.feed(text)\n",
        "    return s.get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYmBQyCi7_Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allowed = [\"TOXICITY\",\n",
        "           \"SEVERE_TOXICITY\",\n",
        "           \"TOXICITY_FAST\",\n",
        "           \"ATTACK_ON_AUTHOR\",\n",
        "           \"ATTACK_ON_COMMENTER\",\n",
        "           \"INCOHERENT\",\n",
        "           \"INFLAMMATORY\",\n",
        "           \"OBSCENE\",\n",
        "           \"OFF_TOPIC\",\n",
        "           \"UNSUBSTANTIAL\",\n",
        "           \"LIKELY_TO_REJECT\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G44z6Zkw8HiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perspective(object):\n",
        "\n",
        "    base_url = \"https://commentanalyzer.googleapis.com/v1alpha1\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def score(self, text, tests=[\"TOXICITY\"], context=None, languages=None, do_not_store=False, token=None, text_type=None):\n",
        "        # data validation\n",
        "        # make sure it's a valid test\n",
        "        # TODO: see if an endpoint that has valid types exists\n",
        "        if isinstance(tests, str):\n",
        "            tests = [tests]\n",
        "        if not isinstance(tests, (list, dict)) or tests is None:\n",
        "            raise ValueError(\"Invalid list/dictionary provided for tests\")\n",
        "        if isinstance(tests, list):\n",
        "            new_data = {}\n",
        "            for test in tests:\n",
        "                new_data[test] = {}\n",
        "            tests = new_data\n",
        "        if text_type:\n",
        "            if text_type.lower() == \"html\":\n",
        "                text = remove_html(text)\n",
        "            elif text_type.lower() == \"md\":\n",
        "                text = remove_html(text, md=True)\n",
        "            else:\n",
        "                raise ValueError(\"{0} is not a valid text_type. Valid options are 'html' or 'md'\".format(str(text_type)))\n",
        "\n",
        "        for test in tests.keys():\n",
        "            if test not in allowed:\n",
        "                warnings.warn(\"{0} might not be accepted as a valid test.\".format(str(test)))\n",
        "            for key in tests[test].keys():\n",
        "                if key not in [\"scoreType\", \"scoreThreshhold\"]:\n",
        "                    raise ValueError(\"{0} is not a valid sub-property for {1}\".format(key, test))\n",
        "\n",
        "        # The API will only grade text less than 3k characters long\n",
        "        if len(text) > 3000:\n",
        "            # TODO: allow disassembly/reassembly of >3000char comments\n",
        "            warnings.warn(\"Perspective only allows 3000 character strings. Only the first 3000 characters will be sent for processing\")\n",
        "            text = text[:3000]\n",
        "        new_langs = []\n",
        "        if languages:\n",
        "            for language in languages:\n",
        "                language = language.lower()\n",
        "                if validate_language(language):\n",
        "                    new_langs.append(language)\n",
        "\n",
        "         # packaging data\n",
        "        url = Perspective.base_url + \"/comments:analyze\"\n",
        "        querystring = {\"key\": self.key}\n",
        "        payload_data = {\"comment\": {\"text\": text}, \"requestedAttributes\": {}}\n",
        "        for test in tests.keys():\n",
        "            payload_data[\"requestedAttributes\"][test] = tests[test]\n",
        "        if new_langs != None:\n",
        "            payload_data[\"languages\"] = new_langs\n",
        "        if do_not_store:\n",
        "            payload_data[\"doNotStore\"] = do_not_store\n",
        "        payload = json.dumps(payload_data)\n",
        "        headers = {'content-type': \"application/json\"}\n",
        "        response = requests.post(url,\n",
        "                            data=payload,\n",
        "                            headers=headers,\n",
        "                            params=querystring)\n",
        "        data = response.json()\n",
        "        if \"error\" in data.keys():\n",
        "            raise PerspectiveAPIException(data[\"error\"][\"message\"])\n",
        "        c = Comment(text, [], token)\n",
        "        base = data[\"attributeScores\"]\n",
        "        for test in tests.keys():\n",
        "            score = base[test][\"summaryScore\"][\"value\"]\n",
        "            score_type = base[test][\"summaryScore\"][\"type\"]\n",
        "            a = Attribute(test, [], score, score_type)\n",
        "            for span in base[test][\"spanScores\"]:\n",
        "                beginning = span[\"begin\"]\n",
        "                end = span[\"end\"]\n",
        "                score = span[\"score\"][\"value\"]\n",
        "                score_type = span[\"score\"][\"type\"]\n",
        "                s = Span(beginning, end, score, score_type, c)\n",
        "                a.spans.append(s)\n",
        "            c.attributes.append(a)\n",
        "        return c\n",
        "\n",
        "class Comment(object):\n",
        "    def __init__(self, text, attributes, token):\n",
        "        self.text = text\n",
        "        self.attributes = attributes\n",
        "        self.token = token\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        if key.upper() not in allowed:\n",
        "            raise ValueError(\"value {0} does not exist\".format(key))\n",
        "        for attr in self.attributes:\n",
        "            if attr.name.lower() == key.lower():\n",
        "                return attr\n",
        "        raise ValueError(\"value {0} not found\".format(key))\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.text\n",
        "\n",
        "    def __repr__(self):\n",
        "        count = 0\n",
        "        num = 0\n",
        "        for attr in self.attributes:\n",
        "            count += attr.score\n",
        "            num += 1\n",
        "        return \"<({0}) {1}>\".format(str(count/num), self.text)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.attributes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "class Attribute(object):\n",
        "      def __init__(self, name, spans, score, score_type):\n",
        "          self.name = name\n",
        "          self.spans = spans\n",
        "          self.score = score\n",
        "          self.score_type = score_type\n",
        "\n",
        "      def __getitem__(self, index):\n",
        "          return self.spans[index]\n",
        "\n",
        "      def __iter__(self):\n",
        "          return iter(self.spans)\n",
        "\n",
        "class Span(object):\n",
        "    def __init__(self, begin, end, score, score_type, comment):\n",
        "        self.begin = begin\n",
        "        self.end = end\n",
        "        self.score = score\n",
        "        self.score_type = score_type\n",
        "        self.comment = comment\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.comment.text[self.begin:self.end]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"<({0}) {1}>\".format(self.score, self.comment.text[self.begin:self.end])\n",
        "\n",
        "class PerspectiveAPIException(Exception):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9rrXMxR8mZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ee544fdf-cd2f-4926-80e5-dbbe84200c56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VceY-2jKPRG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ad442534-e0d0-41c6-9260-f384fccccfb6"
      },
      "source": [
        "%cd './gdrive/My Drive/Colab Notebooks/CS263/'     \n",
        "!pip install cache-magic\n",
        "import cache_magic\n",
        "!mkdir .cache\n",
        "!ln -s './gdrive/My Drive/Colab Notebooks/CS263/.cache' /content/.cache"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/CS263\n",
            "Collecting cache-magic\n",
            "  Downloading https://files.pythonhosted.org/packages/03/94/4cbb25895b80704027453fca297825c0b5924b4ba7533329e0b32a4905a2/cache-magic-1.0.4.tar.gz\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from cache-magic) (1.6.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from cache-magic) (5.5.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from cache-magic) (0.8.7)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->cache-magic) (1.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->cache-magic) (0.34.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (46.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->cache-magic) (2.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->cache-magic) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->cache-magic) (0.1.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->cache-magic) (0.6.0)\n",
            "Building wheels for collected packages: cache-magic\n",
            "  Building wheel for cache-magic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cache-magic: filename=cache_magic-1.0.4-cp36-none-any.whl size=6698 sha256=b9a57977b4e4380cba88376aea0c659f3eac9b90b599e16e79fb528b652803ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/3a/44/00b6aea43fe9fcd0c86bbcf33b7e45d167a6b6a1803983325e\n",
            "Successfully built cache-magic\n",
            "Installing collected packages: cache-magic\n",
            "Successfully installed cache-magic-1.0.4\n",
            "mkdir: cannot create directory ‘.cache’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5eSSG9UPebw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9207ea3a-de77-415b-a6f6-f63044054a69"
      },
      "source": [
        "train_df = pd.read_csv('./toxic_dataset/train1.csv')\n",
        "comments = train_df['comment_text']\n",
        "targets = train_df['target']\n",
        "severe_toxicities = train_df['severe_toxicity']\n",
        "obscenities = train_df['obscene']\n",
        "del train_df\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvIUkLdVR5mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3e621ca9-91a6-431c-c963-e42880b2cb0a"
      },
      "source": [
        "obscenities"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          0.000000\n",
              "1          0.000000\n",
              "2          0.000000\n",
              "3          0.000000\n",
              "4          0.000000\n",
              "             ...   \n",
              "1804869    0.000000\n",
              "1804870    0.000000\n",
              "1804871    0.000000\n",
              "1804872    0.030303\n",
              "1804873    0.000000\n",
              "Name: obscene, Length: 1804874, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1wcLjWaPsD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "google_api_key = \"AIzaSyAb2Mzded8lqAPJ3YwjC9kOJgk9gO7XPiI\"\n",
        "client = Perspective(google_api_key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5K1KP13QaTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4d6d51d8-b2f6-487c-949a-c4d84db92706"
      },
      "source": [
        "toxicity_scores = []\n",
        "severe_toxicity_scores = []\n",
        "obscenity_scores = []\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "print(\"                         EXAMPLE WORKING OF PERSPECTIVE API                          \")\n",
        "print(\"                         ----------------------------------                          \")\n",
        "print(\"\")\n",
        "comment = 'Quiet! you i.diot' \n",
        "toxicity = client.score(comment, tests=[\"TOXICITY\", \"SEVERE_TOXICITY\", \"OBSCENE\"])\n",
        "\n",
        "toxicity_scores.append(toxicity[\"TOXICITY\"].score)\n",
        "severe_toxicity_scores.append(toxicity[\"SEVERE_TOXICITY\"].score)\n",
        "obscenity_scores.append(toxicity[\"OBSCENE\"].score)\n",
        "        \n",
        "print(\"COMMENT :\\n\" + comment)\n",
        "print(\"\")\n",
        "print(\"TOXICITY SCORE : \" + str(toxicity[\"TOXICITY\"].score) +\\\n",
        "      f' {Fore.GREEN}CORRECT \\u2714{Style.RESET_ALL}')\n",
        "\n",
        "print(\"SEVERE TOXICITY SCORE : \" + str(toxicity[\"SEVERE_TOXICITY\"].score) +\\\n",
        "      f' {Fore.GREEN}CORRECT \\u2714{Style.RESET_ALL}')\n",
        "print(\"OBSCENITY SCORE : \" + str(toxicity[\"OBSCENE\"].score) +\\\n",
        "      f' {Fore.GREEN}CORRECT \\u2714{Style.RESET_ALL}')\n",
        "print((\"*********************************************************************\"+\\\n",
        "        \"***********************\").replace('*', '-'))\n",
        "print(\"\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         EXAMPLE WORKING OF PERSPECTIVE API                          \n",
            "                         ----------------------------------                          \n",
            "\n",
            "COMMENT :\n",
            "Quiet! you i.diot\n",
            "\n",
            "TOXICITY SCORE : 0.4323854 \u001b[32mCORRECT ✔\u001b[0m\n",
            "SEVERE TOXICITY SCORE : 0.28388166 \u001b[32mCORRECT ✔\u001b[0m\n",
            "OBSCENITY SCORE : 0.17134532 \u001b[32mCORRECT ✔\u001b[0m\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qrPuJRrRXZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}