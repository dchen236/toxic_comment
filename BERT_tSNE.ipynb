{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-tSNE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM26JQAnvb5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd './gdrive/My Drive/Colab Notebooks/CS263/'     \n",
        "!pip install cache-magic\n",
        "import cache_magic\n",
        "!mkdir .cache\n",
        "!ln -s './gdrive/My Drive/Colab Notebooks/CS263/.cache' /content/.cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cUAhLwnwSgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "train = pd.read_csv('./toxic_dataset/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTarYqV-wUm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_final(train):\n",
        "  train['final'] = 0\n",
        "  for i in range(train.shape[0]):\n",
        "    if(train.iloc[i,2] == 1 or train.iloc[i,3] == 1 or train.iloc[i,4] == 1 or train.iloc[i,5] == 1 or train.iloc[i,6] == 1 or train.iloc[i,7] == 1):\n",
        "      print(i)\n",
        "      train.loc[i,'final'] = 1\n",
        "    else:\n",
        "      train.loc[i,'final'] = 0\n",
        "  return train\n",
        "\n",
        "%cache train = make_final(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvUB7nvowUu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diCp8pLywU-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = train['comment_text'][4]\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOyaA9qwVEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfgQGTDiwVKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print (segments_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lp5ofxxwVPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Y7bzFxwVTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUxVppw1wVYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Number of layers:\", len(encoded_layers))\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZwD4wwlwVcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 11\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgl--XZ5wVgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3IdokTywVkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_vecs = encoded_layers[11][0]\n",
        "\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vb4v-9DwVoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_abuse = train.loc[train['final'] == 1, :]\n",
        "train_clean = train.loc[train['final'] == 0, :]\n",
        "\n",
        "train_abuse.reset_index(drop=True, inplace=True)\n",
        "train_clean.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTXX4SUywVr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_sentence_embeddings(train):\n",
        "  embeddings_list = []\n",
        "  for i in range(train.shape[0]):\n",
        "    if(i%10 == 0):\n",
        "      print(i)\n",
        "    text = train['comment_text'][i]\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    if(len(tokenized_text) > 512):\n",
        "      continue\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "#    print(tokens_tensor.size(), segments_tensors.size())\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    token_vecs = encoded_layers[11][0]\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    embeddings_list.append(sentence_embedding)\n",
        "  return embeddings_list\n",
        "\n",
        "%cache toxic_embedding = make_sentence_embeddings(train_abuse)\n",
        "%cache clean_embedding = make_sentence_embeddings(train_clean[:20000])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Axp9-1ExClk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_toxic_embedding = pd.DataFrame(toxic_embedding[:1000])\n",
        "df_clean_embedding = pd.DataFrame(clean_embedding[:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_UI4ffTxC5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qExgcorrxDFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_toxic = tsne.fit_transform(df_toxic_embedding)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0EcDNdIxDMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results_clean = tsne.fit_transform(df_clean_embedding)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7iksCFmxDTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.title(\"t-SNE of embeddings of toxic vs non-toxic comments\")\n",
        "toxic = plt.scatter(tsne_results_toxic[:,0], tsne_results_toxic[:,1], s = 4, c='red')\n",
        "clean = plt.scatter(tsne_results_clean[:,0], tsne_results_clean[:,1], s = 4, c='blue')\n",
        "plt.legend((toxic,clean),\n",
        "           ('Toxic','Non-Toxic'),\n",
        "           scatterpoints=1,\n",
        "           loc='lower left',\n",
        "           ncol=3,\n",
        "           fontsize=16)\n",
        "plt.xlim((-20,20))\n",
        "plt.ylim((-20,20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PRrcVSCxDZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVma2u3NxDen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1VYHmOCxDky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keypBTNExDqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}