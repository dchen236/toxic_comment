{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "BERT_CNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bLsXDiy6JET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd './gdrive/My Drive/Colab Notebooks/CS263/'     \n",
        "!pip install cache-magic\n",
        "import cache_magic\n",
        "!mkdir .cache\n",
        "!ln -s './gdrive/My Drive/Colab Notebooks/CS263/.cache' /content/.cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCFGaFR_6JEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import time\n",
        "from platform import python_version\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSSDIHhX6JEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./toxic_dataset/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulc18SGS6JEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "df = df.sample(frac=1)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HET9whol6JEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTICdMaJ6JEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[:140000].reset_index(drop=True)\n",
        "df_val = df[140000:150000].reset_index(drop=True)\n",
        "df_test = df[150000:].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMf-RKQ_6JEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class = transformers.BertModel\n",
        "tokenizer_class = transformers.BertTokenizer\n",
        "pretrained_weights='bert-base-uncased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLZ3Z8LJ6JEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "bert_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr3er4526JE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgj9q1li6JE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_text(df, max_seq):\n",
        "    return [\n",
        "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.comment_text.values\n",
        "    ]\n",
        "\n",
        "\n",
        "def pad_text(tokenized_text, max_seq):\n",
        "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
        "\n",
        "\n",
        "def tokenize_and_pad_text(df, max_seq):\n",
        "    tokenized_text = tokenize_text(df, max_seq)\n",
        "    padded_text = pad_text(tokenized_text, max_seq)\n",
        "    return torch.tensor(padded_text)\n",
        "\n",
        "\n",
        "def targets_to_tensor(df, target_columns):\n",
        "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_S3fsxL6JE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
        "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
        "test_indices = tokenize_and_pad_text(df_test, max_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmJt7uNl6JE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_indices)[0]  # Models outputs are tuples\n",
        "    x_val = bert_model(val_indices)[0]\n",
        "    x_test = bert_model(test_indices)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY76Bs5h6JE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = targets_to_tensor(df_train, target_columns)\n",
        "y_val = targets_to_tensor(df_val, target_columns)\n",
        "y_test = targets_to_tensor(df_test, target_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq51Wn1H6JFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KimCNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
        "        super(KimCNN, self).__init__()\n",
        "\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        \n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.sigmoid(logit)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YrUnnDm6JFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_num = x_train.shape[1]\n",
        "embed_dim = x_train.shape[2]\n",
        "class_num = y_train.shape[1]\n",
        "kernel_num = 3\n",
        "kernel_sizes = [2, 3, 4]\n",
        "dropout = 0.5\n",
        "static = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VsZIq6C6JFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KimCNN(\n",
        "    embed_num=embed_num,\n",
        "    embed_dim=embed_dim,\n",
        "    class_num=class_num,\n",
        "    kernel_num=kernel_num,\n",
        "    kernel_sizes=kernel_sizes,\n",
        "    dropout=dropout,\n",
        "    static=static,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMR1xrmY6JFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 10\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfZzk5RC6JFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAtgcNRM6JFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss, batch = 0, 1\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
        "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqPcwa_Y6JFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval() # disable dropout for deterministic output\n",
        "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "    y_preds = []\n",
        "    batch = 0\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
        "    y_preds_np = np.array(y_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbUBuUg26JFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_np = df_test[target_columns].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDyHNWg46JFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
        "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
        "df_accuracy.sort_values('auc')[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}